{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py # if you get an error here, you may need to `pip install h5py` first\n",
    "from pint import UnitRegistry # if you get an error here, you may need to `pip install pint` first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HDF5 output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following datasets found in file ../tdac.h5 : ['data_avg', 'data_syn', 'data_var', 'grid', 'params', 'stations', 'timer', 'weights']\n",
      "The following timestamps found:  ['t0', 't1', 't10', 't11', 't12', 't13', 't14', 't15', 't16', 't17', 't18', 't19', 't2', 't20', 't3', 't4', 't5', 't6', 't7', 't8', 't9']\n",
      "The following fields found:  ['height', 'vx', 'vy']\n"
     ]
    }
   ],
   "source": [
    "filename = \"../tdac.h5\"\n",
    "fh = h5py.File(filename,'r')\n",
    "print(\"The following datasets found in file\",filename,\":\",list(fh))\n",
    "if \"data_syn\" in list(fh): print(\"The following timestamps found: \", list(fh[\"data_syn\"]))\n",
    "if \"t0\" in list(fh[\"data_syn\"]): print(\"The following fields found: \", list(fh[\"data_syn\"][\"t0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set these parameters to choose what to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 't1' # Edit this value to plot a different time slice from the list above\n",
    "field = 'height' # Choose from the fields listed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data from the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ureg = UnitRegistry()\n",
    "\n",
    "field_unit = fh[\"data_syn\"][timestamp][field].attrs[\"Unit\"].decode('UTF-8')\n",
    "var_unit = fh[\"data_var\"][timestamp][field].attrs[\"Unit\"].decode('UTF-8')\n",
    "x_unit = fh[\"grid\"][\"x\"].attrs[\"Unit\"].decode('UTF-8')\n",
    "y_unit = fh[\"grid\"][\"y\"].attrs[\"Unit\"].decode('UTF-8')\n",
    "x_st_unit = fh[\"stations\"][\"x\"].attrs[\"Unit\"].decode('UTF-8')\n",
    "y_st_unit = fh[\"stations\"][\"y\"].attrs[\"Unit\"].decode('UTF-8')\n",
    "\n",
    "field_desc = fh[\"data_syn\"][timestamp][field].attrs[\"Description\"].decode('UTF-8')\n",
    "\n",
    "x = (fh[\"grid\"][\"x\"][:] * ureg(x_unit)).to(ureg.km)\n",
    "y = (fh[\"grid\"][\"y\"][:] * ureg(y_unit)).to(ureg.km)\n",
    "z_t = fh[\"data_syn\"][timestamp][field][()] * ureg(field_unit)\n",
    "z_avg = fh[\"data_avg\"][timestamp][field][()] * ureg(field_unit)\n",
    "z_var = fh[\"data_var\"][timestamp][field][()] * ureg(var_unit)\n",
    "z_std = np.sqrt(z_var)\n",
    "x_st = (fh[\"stations\"][\"x\"][:] * ureg(x_st_unit)).to(ureg.km)\n",
    "y_st = (fh[\"stations\"][\"y\"][:] * ureg(y_st_unit)).to(ureg.km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour plots of surface height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (18,6)\n",
    "\n",
    "n_contours = 100\n",
    "zmax = max(np.max(z_t), np.max(z_avg)).magnitude\n",
    "zmin = min(np.min(z_t), np.min(z_avg)).magnitude\n",
    "levels = np.linspace(zmin, zmax, n_contours)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "i1 = ax[0].contourf(x,y,z_t,levels)\n",
    "i2 = ax[1].contourf(x,y,z_avg,levels)\n",
    "i3 = ax[2].contourf(x,y,z_std,n_contours)\n",
    "\n",
    "images = [i1,i2,i3]\n",
    "\n",
    "ax[0].set_title(f\"True {field_desc.lower()} [{z_t.units:~}]\")\n",
    "ax[1].set_title(f\"Assimilated {field_desc.lower()} [{z_avg.units:~}]\")\n",
    "ax[2].set_title(f\"Std of assimilated {field_desc.lower()} [{z_std.units:~}]\")\n",
    "\n",
    "for a,im in zip(ax,images):\n",
    "    a.scatter(x_st, y_st, color = 'r', marker = '*')\n",
    "    a.set_xlabel(f\"x [{y.units:~}]\")\n",
    "    a.set_ylabel(f\"y [{x.units:~}]\")\n",
    "    plt.colorbar(im,ax=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot of particle weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = fh[\"weights\"][timestamp][:]\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].plot(weights, '*')\n",
    "ax[1].plot(weights, '*')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel('Particle ID')\n",
    "    a.set_ylabel('Weight ('+a.get_yscale() + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series of Estimated Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess = list()\n",
    "for ts in list(fh[\"weights\"])[1:]:\n",
    "    ess.append(1/sum(fh[\"weights\"][ts][:]**2))\n",
    "fig = plt.figure()\n",
    "t = np.arange(1,np.size(ess)+1)\n",
    "plt.plot(t,ess)\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Estimated Sample Size (1 / sum(weight^2))');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
