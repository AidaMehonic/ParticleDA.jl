{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using HDF5\n",
    "using Unitful\n",
    "using UnitfulRecipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HDF5 output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"particle_da.h5\"\n",
    "fh = h5open(filename, \"r\")\n",
    "\n",
    "println(\"The following datasets found in file \", filename, \": \", keys(fh))\n",
    "haskey(fh, \"data_syn\") && println(\"The following timestamps found: \", keys(fh[\"data_syn\"]))\n",
    "haskey(fh[\"data_syn\"], \"t0\") && println(\"The following fields found: \", keys(fh[\"data_syn\"][\"t0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set these parameters to choose what to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"t1\" # Edit this value to plot a different time slice from the list above\n",
    "field = \"height\" # Choose from the fields listed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data from the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_unit = read(fh[\"data_syn\"][timestamp][field][\"Unit\"])\n",
    "var_unit = read(fh[\"data_var\"][timestamp][field][\"Unit\"])\n",
    "x_unit = read(fh[\"grid\"][\"x\"][\"Unit\"])\n",
    "y_unit = read(fh[\"grid\"][\"y\"][\"Unit\"])\n",
    "x_st_unit = read(fh[\"stations\"][\"x\"][\"Unit\"])\n",
    "y_st_unit = read(fh[\"stations\"][\"y\"][\"Unit\"])\n",
    "\n",
    "field_desc = read(fh[\"data_syn\"][timestamp][field][\"Description\"])\n",
    "\n",
    "x = read(fh[\"grid\"][\"x\"]) .* uparse(x_unit) .|> u\"km\"\n",
    "y = read(fh[\"grid\"][\"y\"]) .* uparse(y_unit) .|> u\"km\"\n",
    "z_t = read(fh[\"data_syn\"][timestamp][field]) .* uparse(field_unit)\n",
    "z_avg = read(fh[\"data_avg\"][timestamp][field]) .* uparse(field_unit)\n",
    "z_var = read(fh[\"data_var\"][timestamp][field]) .* uparse(var_unit)\n",
    "z_std = sqrt.(z_var)\n",
    "x_st = read(fh[\"stations\"][\"x\"]) .* uparse(x_st_unit) .|> u\"km\"\n",
    "y_st = read(fh[\"stations\"][\"y\"]) .* uparse(y_st_unit) .|> u\"km\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour plots of surface height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_data(x, y, z_t, z_avg, z_std, field_desc)\n",
    "    n_contours = 100\n",
    "    zmax = max(maximum(z_t), maximum(z_avg))\n",
    "    zmin = min(minimum(z_t), minimum(z_avg))\n",
    "    levels = range(zmin, zmax; length=n_contours)\n",
    "\n",
    "    p1 = heatmap(x, y, z_t; title=\"True $(lowercase(field_desc))\")\n",
    "    p2 = heatmap(x, y, z_avg; title=\"Assimilated $(lowercase(field_desc))\")\n",
    "    p3 = heatmap(x, y, z_std; title=\"Std of assimilated $(lowercase(field_desc))\")\n",
    "\n",
    "    for (i, plt) in enumerate((p1, p2, p3))\n",
    "        # Set labels\n",
    "        plot!(plt; xlabel=\"x\", ylabel=\"y\")\n",
    "        # Set range of color bar for first two plots\n",
    "        i ∈ (1, 2) && plot!(plt; clims=(ustrip(zmin), ustrip(zmax)))\n",
    "        # Add the positions of the stations\n",
    "        scatter!(plt, x_st, y_st, color=:red, marker=:star, label=\"\")\n",
    "    end\n",
    "\n",
    "    plot(p1, p2, p3; titlefontsize=8, guidefontsize=8)\n",
    "end\n",
    "\n",
    "plot_data(x, y, z_t, z_avg, z_std, field_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot of particle weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = read(fh[\"weights\"][timestamp])\n",
    "\n",
    "p1 = scatter(weights, marker=:star)\n",
    "p2 = scatter(weights, marker=:star, yscale=:log10)\n",
    "\n",
    "for plt in (p1, p2)\n",
    "    plot!(plt; xlabel=\"Particle ID\", ylabel=\"Weight\")\n",
    "end\n",
    "\n",
    "plot(p1, p2, label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series of Estimated Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot([1 / sum(read(w) .^ 2) for w in fh[\"weights\"]];\n",
    "     label=\"\", marker=:o, xlabel=\"Time step\", ylabel=\"Estimated Sample Size (1 / sum(weight^2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = @animate for timestamp ∈ keys(fh[\"data_syn\"])\n",
    "    z_t = read(fh[\"data_syn\"][timestamp][field]) .* uparse(field_unit)\n",
    "    z_avg = read(fh[\"data_avg\"][timestamp][field]) .* uparse(field_unit)\n",
    "    z_var = read(fh[\"data_var\"][timestamp][field]) .* uparse(var_unit)\n",
    "    z_std = sqrt.(z_var)\n",
    "\n",
    "    plot_data(x, y, z_t, z_avg, z_std, field_desc)\n",
    "end\n",
    "\n",
    "mp4(animation, \"animation_jl.mp4\"; fps=5)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
